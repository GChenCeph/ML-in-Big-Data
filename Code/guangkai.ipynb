{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install jdcal\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import jdcal\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "state_to_id = {\n",
    "    \"AL\": 1, \"AZ\": 2, \"AR\": 3, \"CA\": 4, \"CO\": 5,\n",
    "    \"CT\": 6, \"DE\": 7, \"FL\": 8, \"GA\": 9, \"ID\": 10,\n",
    "    \"IL\": 11, \"IN\": 12, \"IA\": 13, \"KS\": 14, \"KY\": 15,\n",
    "    \"LA\": 16, \"ME\": 17, \"MD\": 18, \"MA\": 19, \"MI\": 20,\n",
    "    \"MN\": 21, \"MS\": 22, \"MO\": 23, \"MT\": 24, \"NE\": 25,\n",
    "    \"NV\": 26, \"NH\": 27, \"NJ\": 28, \"NM\": 29, \"NY\": 30,\n",
    "    \"NC\": 31, \"ND\": 32, \"OH\": 33, \"OK\": 34, \"OR\": 35,\n",
    "    \"PA\": 36, \"RI\": 37, \"SC\": 38, \"SD\": 39, \"TN\": 40,\n",
    "    \"TX\": 41, \"UT\": 42, \"VT\": 43, \"VA\": 44, \"WA\": 45,\n",
    "    \"WV\": 46, \"WI\": 47, \"WY\": 48, \"HI\": 49, \"AK\": 50\n",
    "}\n",
    "\n",
    "\n",
    "def julian_to_gregorian(julian_date):\n",
    "    year, month, day, frac = jdcal.jd2gcal(jdcal.MJD_0, julian_date - jdcal.MJD_0)\n",
    "    return datetime(year, month, day)\n",
    "\n",
    "\n",
    "conn = sqlite3.connect(\"../Data/FPA_FOD_20170508.sqlite\")\n",
    "df = pd.read_sql_query(\"SELECT STATE, DISCOVERY_DATE FROM Fires\", conn) #\"SELECT * FROM 'Fires'\",conn\n",
    "\n",
    "df['DISCOVERY_DATE'] = df['DISCOVERY_DATE'].apply(julian_to_gregorian)\n",
    "\n",
    "df['year'] = df['DISCOVERY_DATE'].dt.year\n",
    "df['month'] = df['DISCOVERY_DATE'].dt.month\n",
    "\n",
    "df = df.drop('DISCOVERY_DATE', axis=1)\n",
    "\n",
    "df['STATE'] = df['STATE'].map(state_to_id)\n",
    "\n",
    "df = df.dropna(subset=['STATE'])\n",
    "\n",
    "df['STATE'] = df['STATE'].astype(int)\n",
    "\n",
    "# Rename the STATE column to state\n",
    "df.rename(columns={'STATE': 'state'}, inplace=True)\n",
    "\n",
    "df.to_csv(\"../Data/data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processiong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define state codes and month codes\n",
    "state_codes = {\n",
    "    \"Alabama\": 1, \"Arizona\": 2, \"Arkansas\": 3, \"California\": 4, \"Colorado\": 5,\n",
    "    \"Connecticut\": 6, \"Delaware\": 7, \"Florida\": 8, \"Georgia\": 9, \"Idaho\": 10,\n",
    "    \"Illinois\": 11, \"Indiana\": 12, \"Iowa\": 13, \"Kansas\": 14, \"Kentucky\": 15,\n",
    "    \"Louisiana\": 16, \"Maine\": 17, \"Maryland\": 18, \"Massachusetts\": 19, \"Michigan\": 20,\n",
    "    \"Minnesota\": 21, \"Mississippi\": 22, \"Missouri\": 23, \"Montana\": 24, \"Nebraska\": 25,\n",
    "    \"Nevada\": 26, \"New Hampshire\": 27, \"New Jersey\": 28, \"New Mexico\": 29, \"New York\": 30,\n",
    "    \"North Carolina\": 31, \"North Dakota\": 32, \"Ohio\": 33, \"Oklahoma\": 34, \"Oregon\": 35,\n",
    "    \"Pennsylvania\": 36, \"Rhode Island\": 37, \"South Carolina\": 38, \"South Dakota\": 39,\n",
    "    \"Tennessee\": 40, \"Texas\": 41, \"Utah\": 42, \"Vermont\": 43, \"Virginia\": 44,\n",
    "    \"Washington\": 45, \"West Virginia\": 46, \"Wisconsin\": 47, \"Wyoming\": 48, \"Alaska\": 50\n",
    "}\n",
    "\n",
    "month_codes = {\n",
    "    \"January\": 1, \"February\": 2, \"March\": 3, \"April\": 4, \"May\": 5, \"June\": 6, \n",
    "    \"July\": 7, \"August\": 8, \"September\": 9, \"October\": 10, \"November\": 11, \"December\": 12\n",
    "}\n",
    "\n",
    "# Function to categorize fire count\n",
    "def categorize_fire_count(fire_count):\n",
    "    if fire_count <= 3:\n",
    "        return 1\n",
    "    elif fire_count <= 29:\n",
    "        return 2\n",
    "    elif fire_count <= 141:\n",
    "        return 3\n",
    "    elif fire_count <= 348:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "# Load the wildfire data\n",
    "wilds = pd.read_csv('../Data/data.csv')\n",
    "\n",
    "# Preprocess to create a summary of fire counts per state and year for each month\n",
    "fire_summary = wilds.groupby(['state', 'year', 'month']).size().reset_index(name='count')\n",
    "fire_summary_dict = {(row['state'], row['year'], row['month']): row['count'] for _, row in fire_summary.iterrows()}\n",
    "\n",
    "# File paths of datasets to be processed\n",
    "file_paths = [\n",
    "    'climdiv-pcpnst-v1.0.0-20231106.txt', 'climdiv-pdsist-v1.0.0-20231106.txt',\n",
    "    'climdiv-phdist-v1.0.0-20231106.txt', 'climdiv-sp01st-v1.0.0-20231106.txt',\n",
    "    'climdiv-sp02st-v1.0.0-20231106.txt', 'climdiv-sp06st-v1.0.0-20231106.txt',\n",
    "    'climdiv-sp12st-v1.0.0-20231106.txt', 'climdiv-sp24st-v1.0.0-20231106.txt',\n",
    "    'climdiv-tmaxst-v1.0.0-20231106.txt', 'climdiv-tminst-v1.0.0-20231106.txt',\n",
    "    'climdiv-tmpcst-v1.0.0-20231106.txt', 'climdiv-zndxst-v1.0.0-20231106.txt'\n",
    "]\n",
    "\n",
    "# Initialize DataFrame to store the combined data\n",
    "combined_df = None\n",
    "\n",
    "# Process each file and merge into combined_df\n",
    "for file_path in file_paths:\n",
    "    data = []\n",
    "    with open('../Data/'+file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            words = line.split()\n",
    "            state_id = int(words[0][:3])\n",
    "            year_val = int(words[0][-4:])\n",
    "            monthly_data = [float(word) for word in words[1:13]]\n",
    "            data.append([state_id, year_val] + monthly_data)\n",
    "\n",
    "    name = file_path.split('/')[-1].split('-')[1]\n",
    "    columns = ['state', 'year'] + [f'{name}_m{i}' for i in range(1, 13)]\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    if combined_df is None:\n",
    "        combined_df = df\n",
    "    else:\n",
    "        combined_df = pd.merge(combined_df, df, on=['state', 'year'])\n",
    "\n",
    "# Categorize fire counts for each month\n",
    "for month in range(1, 13):\n",
    "    combined_df[f'f{month}'] = combined_df.apply(\n",
    "        lambda row: categorize_fire_count(\n",
    "            fire_summary_dict.get((row['state'], row['year'], month), 0)\n",
    "        ), axis=1\n",
    "    )\n",
    "\n",
    "# Split the dataset into training, reference, and testing datasets\n",
    "training_df = combined_df[(combined_df['year'] >= 1992) & (combined_df['year'] <= 2013) & (combined_df['state'] < 49)]\n",
    "reference = combined_df[(combined_df['year'] >= 2014) & (combined_df['year'] <= 2015) & (combined_df['state'] < 49)]\n",
    "testing_df = reference.copy()\n",
    "\n",
    "# Set fire counts to 0 in the testing dataset\n",
    "for i in range(1, 13):\n",
    "    testing_df[f'f{i}'] = 0\n",
    "\n",
    "# Save the datasets\n",
    "training_df.to_csv('../Data/training.csv', index=False)\n",
    "reference.to_csv('../Data/reference.csv', index=False)\n",
    "testing_df.to_csv('../Data/testing.csv', index=False)\n",
    "\n",
    "print(\"Datasets saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points in testing set: 96\n",
      "\n",
      "Number of anomalies detected: 39\n",
      "\n",
      "\n",
      "Anomaly Detection Comparison with Reference Data:\n",
      "\n",
      "Month 1 - Detected Anomalies: 0, Actual Fires: 33\n",
      "\n",
      "Month 2 - Detected Anomalies: 0, Actual Fires: 31\n",
      "\n",
      "Month 3 - Detected Anomalies: 0, Actual Fires: 15\n",
      "\n",
      "Month 4 - Detected Anomalies: 0, Actual Fires: 3\n",
      "\n",
      "Month 5 - Detected Anomalies: 0, Actual Fires: 8\n",
      "\n",
      "Month 6 - Detected Anomalies: 0, Actual Fires: 14\n",
      "\n",
      "Month 7 - Detected Anomalies: 0, Actual Fires: 20\n",
      "\n",
      "Month 8 - Detected Anomalies: 0, Actual Fires: 19\n",
      "\n",
      "Month 9 - Detected Anomalies: 0, Actual Fires: 16\n",
      "\n",
      "Month 10 - Detected Anomalies: 0, Actual Fires: 13\n",
      "\n",
      "Month 11 - Detected Anomalies: 0, Actual Fires: 15\n",
      "\n",
      "Month 12 - Detected Anomalies: 0, Actual Fires: 43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_df = pd.read_csv('../Data/training.csv')\n",
    "test_df = pd.read_csv('../Data/testing.csv')\n",
    "reference_df = pd.read_csv('../Data/reference.csv')\n",
    "\n",
    "X_train = train_df.drop(columns=[f'f{i}' for i in range(1, 13)])\n",
    "X_test = test_df.drop(columns=[f'f{i}' for i in range(1, 13)])\n",
    "y_reference = reference_df[[f'f{i}' for i in range(1, 13)]]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "iso_forest = IsolationForest(n_estimators=100, contamination=0.5, random_state=42)\n",
    "iso_forest.fit(X_train_scaled)\n",
    "\n",
    "anomalies = iso_forest.predict(X_test_scaled)\n",
    "\n",
    "test_df['anomaly'] = anomalies\n",
    "\n",
    "anomalous_data = test_df[test_df['anomaly'] == -1]\n",
    "\n",
    "\n",
    "print(f\"Total data points in testing set: {len(test_df)}\\n\")\n",
    "print(f\"Number of anomalies detected: {len(anomalous_data)}\\n\")\n",
    "\n",
    "print(\"\\nAnomaly Detection Comparison with Reference Data:\\n\")\n",
    "for i in range(1, 13):\n",
    "    anomaly_count = anomalous_data[anomalous_data[f'f{i}'] == 1].shape[0]\n",
    "    actual_fire_count = y_reference[y_reference[f'f{i}'] == 1].shape[0]\n",
    "    print(f\"Month {i} - Detected Anomalies: {anomaly_count}, Actual Fires: {actual_fire_count}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for each month:\n",
      "\n",
      "\n",
      "Month 1 Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      1.00      0.66        33\n",
      "           2       0.50      0.07      0.13        27\n",
      "           3       0.19      0.25      0.21        12\n",
      "           4       0.62      0.31      0.42        16\n",
      "           5       1.00      0.12      0.22         8\n",
      "\n",
      "    accuracy                           0.46        96\n",
      "   macro avg       0.56      0.35      0.33        96\n",
      "weighted avg       0.52      0.46      0.38        96\n",
      "\n",
      "Accuracy for Month 1: 0.4583333333333333\n",
      "\n",
      "\n",
      "Month 2 Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.97      0.71        31\n",
      "           2       0.73      0.31      0.43        26\n",
      "           3       0.25      0.31      0.28        13\n",
      "           4       0.67      0.24      0.35        17\n",
      "           5       0.50      0.56      0.53         9\n",
      "\n",
      "    accuracy                           0.53        96\n",
      "   macro avg       0.54      0.47      0.46        96\n",
      "weighted avg       0.58      0.53      0.50        96\n",
      "\n",
      "Accuracy for Month 2: 0.53125\n",
      "\n",
      "\n",
      "Month 3 Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.67      0.61        15\n",
      "           2       0.47      0.84      0.60        19\n",
      "           3       0.23      0.23      0.23        22\n",
      "           4       1.00      0.04      0.07        27\n",
      "           5       0.38      0.62      0.47        13\n",
      "\n",
      "    accuracy                           0.42        96\n",
      "   macro avg       0.53      0.48      0.40        96\n",
      "weighted avg       0.56      0.42      0.35        96\n",
      "\n",
      "Accuracy for Month 3: 0.4166666666666667\n",
      "\n",
      "\n",
      "Month 4 Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.17      0.33      0.22         3\n",
      "           2       0.35      0.57      0.43        14\n",
      "           3       0.69      0.59      0.64        37\n",
      "           4       0.39      0.28      0.33        25\n",
      "           5       0.41      0.41      0.41        17\n",
      "\n",
      "    accuracy                           0.47        96\n",
      "   macro avg       0.40      0.44      0.41        96\n",
      "weighted avg       0.50      0.47      0.47        96\n",
      "\n",
      "Accuracy for Month 4: 0.46875\n",
      "\n",
      "\n",
      "Month 5 Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.75      0.38         8\n",
      "           2       0.12      0.13      0.12        15\n",
      "           3       0.69      0.62      0.65        50\n",
      "           4       0.33      0.08      0.13        12\n",
      "           5       0.86      0.55      0.67        11\n",
      "\n",
      "    accuracy                           0.48        96\n",
      "   macro avg       0.45      0.43      0.39        96\n",
      "weighted avg       0.54      0.48      0.48        96\n",
      "\n",
      "Accuracy for Month 5: 0.4791666666666667\n",
      "\n",
      "\n",
      "Month 6 Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.93      0.58        14\n",
      "           2       0.87      0.34      0.49        38\n",
      "           3       0.48      0.76      0.59        21\n",
      "           4       0.67      0.57      0.62        14\n",
      "           5       1.00      0.56      0.71         9\n",
      "\n",
      "    accuracy                           0.57        96\n",
      "   macro avg       0.69      0.63      0.60        96\n",
      "weighted avg       0.70      0.57      0.56        96\n",
      "\n",
      "Accuracy for Month 6: 0.5729166666666666\n",
      "\n",
      "\n",
      "Month 7 Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.85      0.69        20\n",
      "           2       0.67      0.50      0.57        20\n",
      "           3       0.61      0.74      0.67        23\n",
      "           4       0.62      0.28      0.38        18\n",
      "           5       0.69      0.73      0.71        15\n",
      "\n",
      "    accuracy                           0.62        96\n",
      "   macro avg       0.63      0.62      0.61        96\n",
      "weighted avg       0.63      0.62      0.61        96\n",
      "\n",
      "Accuracy for Month 7: 0.625\n",
      "\n",
      "\n",
      "Month 8 Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.95      0.64        19\n",
      "           2       0.57      0.17      0.27        23\n",
      "           3       0.59      0.68      0.63        28\n",
      "           4       0.50      0.27      0.35        11\n",
      "           5       0.86      0.80      0.83        15\n",
      "\n",
      "    accuracy                           0.58        96\n",
      "   macro avg       0.60      0.57      0.54        96\n",
      "weighted avg       0.60      0.58      0.55        96\n",
      "\n",
      "Accuracy for Month 8: 0.5833333333333334\n",
      "\n",
      "\n",
      "Month 9 Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.94      0.56        16\n",
      "           2       0.46      0.20      0.28        30\n",
      "           3       0.73      0.77      0.75        35\n",
      "           4       0.50      0.30      0.37        10\n",
      "           5       1.00      0.40      0.57         5\n",
      "\n",
      "    accuracy                           0.55        96\n",
      "   macro avg       0.62      0.52      0.51        96\n",
      "weighted avg       0.58      0.55      0.52        96\n",
      "\n",
      "Accuracy for Month 9: 0.5520833333333334\n",
      "\n",
      "\n",
      "Month 10 Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.54      0.41        13\n",
      "           2       0.53      0.50      0.52        32\n",
      "           3       0.53      0.70      0.61        33\n",
      "           4       0.00      0.00      0.00        12\n",
      "           5       0.50      0.17      0.25         6\n",
      "\n",
      "    accuracy                           0.49        96\n",
      "   macro avg       0.38      0.38      0.36        96\n",
      "weighted avg       0.44      0.49      0.45        96\n",
      "\n",
      "Accuracy for Month 10: 0.4895833333333333\n",
      "\n",
      "\n",
      "Month 11 Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.67      0.47        15\n",
      "           2       0.65      0.58      0.61        38\n",
      "           3       0.50      0.56      0.53        27\n",
      "           4       0.33      0.08      0.13        12\n",
      "           5       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.50        96\n",
      "   macro avg       0.37      0.38      0.35        96\n",
      "weighted avg       0.49      0.50      0.48        96\n",
      "\n",
      "Accuracy for Month 11: 0.5\n",
      "\n",
      "\n",
      "Month 12 Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.95      0.77        43\n",
      "           2       0.38      0.18      0.24        28\n",
      "           3       0.47      0.50      0.48        16\n",
      "           4       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.56        96\n",
      "   macro avg       0.37      0.41      0.37        96\n",
      "weighted avg       0.48      0.56      0.50        96\n",
      "\n",
      "Accuracy for Month 12: 0.5625\n",
      "\n",
      "\n",
      "Average Accuracy Across All Months: 0.5199652777777777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('../Data/training.csv')\n",
    "df_test = pd.read_csv('../Data/testing.csv')\n",
    "df_reference = pd.read_csv('../Data/reference.csv')\n",
    "\n",
    "X_train = df.drop(columns=[f'f{i}' for i in range(1, 13)])\n",
    "y_train = df[[f'f{i}' for i in range(1, 13)]]\n",
    "X_test = df_test.drop(columns=[f'f{i}' for i in range(1, 13)])\n",
    "y_test = df_reference[[f'f{i}' for i in range(1, 13)]]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "predictions = rf_classifier.predict(X_test_scaled)\n",
    "\n",
    "print(\"Classification Report for each month:\\n\")\n",
    "overall_accuracy = 0\n",
    "for i in range(1, 13):\n",
    "    report = classification_report(y_test[f'f{i}'], predictions[:, i-1], zero_division=0)\n",
    "    print(f\"\\nMonth {i} Report:\\n\")\n",
    "    print(report)\n",
    "    accuracy = accuracy_score(y_test[f'f{i}'], predictions[:, i-1])\n",
    "    overall_accuracy += accuracy\n",
    "    print(f\"Accuracy for Month {i}: {accuracy}\\n\")\n",
    "\n",
    "overall_accuracy /= 12\n",
    "print(f\"\\nAverage Accuracy Across All Months: {overall_accuracy}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 1.7639490365982056\n",
      "Epoch 2/100, Loss: 1.4313043355941772\n",
      "Epoch 3/100, Loss: 0.9805805087089539\n",
      "Epoch 4/100, Loss: 1.0355020761489868\n",
      "Epoch 5/100, Loss: 0.6647326350212097\n",
      "Epoch 6/100, Loss: 0.6592243313789368\n",
      "Epoch 7/100, Loss: 0.6300965547561646\n",
      "Epoch 8/100, Loss: 0.8259527087211609\n",
      "Epoch 9/100, Loss: 0.5498923063278198\n",
      "Epoch 10/100, Loss: 0.6521825194358826\n",
      "Epoch 11/100, Loss: 1.1913474798202515\n",
      "Epoch 12/100, Loss: 0.8576253056526184\n",
      "Epoch 13/100, Loss: 0.43662795424461365\n",
      "Epoch 14/100, Loss: 0.47251200675964355\n",
      "Epoch 15/100, Loss: 0.44483694434165955\n",
      "Epoch 16/100, Loss: 0.35314902663230896\n",
      "Epoch 17/100, Loss: 0.3163565695285797\n",
      "Epoch 18/100, Loss: 0.5070359110832214\n",
      "Epoch 19/100, Loss: 0.3913142681121826\n",
      "Epoch 20/100, Loss: 0.3484780490398407\n",
      "Epoch 21/100, Loss: 0.32110270857810974\n",
      "Epoch 22/100, Loss: 0.37369778752326965\n",
      "Epoch 23/100, Loss: 0.29563072323799133\n",
      "Epoch 24/100, Loss: 0.20488905906677246\n",
      "Epoch 25/100, Loss: 0.28479254245758057\n",
      "Epoch 26/100, Loss: 0.24202817678451538\n",
      "Epoch 27/100, Loss: 0.20693188905715942\n",
      "Epoch 28/100, Loss: 0.2711259722709656\n",
      "Epoch 29/100, Loss: 0.24199096858501434\n",
      "Epoch 30/100, Loss: 0.2395993322134018\n",
      "Epoch 31/100, Loss: 0.26477059721946716\n",
      "Epoch 32/100, Loss: 0.19102643430233002\n",
      "Epoch 33/100, Loss: 0.17843957245349884\n",
      "Epoch 34/100, Loss: 0.1989910751581192\n",
      "Epoch 35/100, Loss: 0.18884627521038055\n",
      "Epoch 36/100, Loss: 0.32105499505996704\n",
      "Epoch 37/100, Loss: 0.24468308687210083\n",
      "Epoch 38/100, Loss: 0.21935848891735077\n",
      "Epoch 39/100, Loss: 0.1866341084241867\n",
      "Epoch 40/100, Loss: 0.297404408454895\n",
      "Epoch 41/100, Loss: 0.17682433128356934\n",
      "Epoch 42/100, Loss: 0.16440831124782562\n",
      "Epoch 43/100, Loss: 0.17744773626327515\n",
      "Epoch 44/100, Loss: 0.1965581327676773\n",
      "Epoch 45/100, Loss: 0.15220022201538086\n",
      "Epoch 46/100, Loss: 0.21731460094451904\n",
      "Epoch 47/100, Loss: 0.1579992175102234\n",
      "Epoch 48/100, Loss: 0.1547507345676422\n",
      "Epoch 49/100, Loss: 0.12299001961946487\n",
      "Epoch 50/100, Loss: 0.14073316752910614\n",
      "Epoch 51/100, Loss: 0.27004703879356384\n",
      "Epoch 52/100, Loss: 0.14688360691070557\n",
      "Epoch 53/100, Loss: 0.30607330799102783\n",
      "Epoch 54/100, Loss: 0.19175277650356293\n",
      "Epoch 55/100, Loss: 0.11394333839416504\n",
      "Epoch 56/100, Loss: 0.12968623638153076\n",
      "Epoch 57/100, Loss: 0.13041089475154877\n",
      "Epoch 58/100, Loss: 0.15229414403438568\n",
      "Epoch 59/100, Loss: 0.13675247132778168\n",
      "Epoch 60/100, Loss: 0.1429775357246399\n",
      "Epoch 61/100, Loss: 0.10189305990934372\n",
      "Epoch 62/100, Loss: 0.1309998482465744\n",
      "Epoch 63/100, Loss: 0.11165312677621841\n",
      "Epoch 64/100, Loss: 0.13465414941310883\n",
      "Epoch 65/100, Loss: 0.13249020278453827\n",
      "Epoch 66/100, Loss: 0.10834795236587524\n",
      "Epoch 67/100, Loss: 0.13102291524410248\n",
      "Epoch 68/100, Loss: 0.20591986179351807\n",
      "Epoch 69/100, Loss: 0.1853983849287033\n",
      "Epoch 70/100, Loss: 0.14282356202602386\n",
      "Epoch 71/100, Loss: 0.16563622653484344\n",
      "Epoch 72/100, Loss: 0.10809513181447983\n",
      "Epoch 73/100, Loss: 0.10526970773935318\n",
      "Epoch 74/100, Loss: 0.10659175366163254\n",
      "Epoch 75/100, Loss: 0.10782399028539658\n",
      "Epoch 76/100, Loss: 0.09490024298429489\n",
      "Epoch 77/100, Loss: 0.09509089589118958\n",
      "Epoch 78/100, Loss: 0.10342398285865784\n",
      "Epoch 79/100, Loss: 0.11808279156684875\n",
      "Epoch 80/100, Loss: 0.11710482090711594\n",
      "Epoch 81/100, Loss: 0.09756291657686234\n",
      "Epoch 82/100, Loss: 0.09796800464391708\n",
      "Epoch 83/100, Loss: 0.07053101062774658\n",
      "Epoch 84/100, Loss: 0.07343434542417526\n",
      "Epoch 85/100, Loss: 0.11161573976278305\n",
      "Epoch 86/100, Loss: 0.10237496346235275\n",
      "Epoch 87/100, Loss: 0.10291550308465958\n",
      "Epoch 88/100, Loss: 0.0933649018406868\n",
      "Epoch 89/100, Loss: 0.07953798025846481\n",
      "Epoch 90/100, Loss: 0.09596701711416245\n",
      "Epoch 91/100, Loss: 0.08801573514938354\n",
      "Epoch 92/100, Loss: 0.08995532989501953\n",
      "Epoch 93/100, Loss: 0.0731753259897232\n",
      "Epoch 94/100, Loss: 0.10446202009916306\n",
      "Epoch 95/100, Loss: 0.07294634729623795\n",
      "Epoch 96/100, Loss: 0.06838656216859818\n",
      "Epoch 97/100, Loss: 0.07489854097366333\n",
      "Epoch 98/100, Loss: 0.07177525013685226\n",
      "Epoch 99/100, Loss: 0.07061278074979782\n",
      "Epoch 100/100, Loss: 0.09378182142972946\n",
      "Average Testing Loss: 7.309586763381958\n",
      "Monthly Accuracy:\n",
      "\n",
      "Month 1: 0.44\n",
      "\n",
      "Month 2: 0.51\n",
      "\n",
      "Month 3: 0.31\n",
      "\n",
      "Month 4: 0.39\n",
      "\n",
      "Month 5: 0.35\n",
      "\n",
      "Month 6: 0.46\n",
      "\n",
      "Month 7: 0.54\n",
      "\n",
      "Month 8: 0.34\n",
      "\n",
      "Month 9: 0.48\n",
      "\n",
      "Month 10: 0.42\n",
      "\n",
      "Month 11: 0.36\n",
      "\n",
      "Month 12: 0.51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Neural Network Model\n",
    "class RegressionNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(RegressionNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, output_size)\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "        nn.init.kaiming_normal_(self.fc2.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Custom Dataset\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]\n",
    "\n",
    "# Load Data\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    features = df.drop(columns=[f'f{i}' for i in range(1, 13)]).values\n",
    "    targets = df[[f'f{i}' for i in range(1, 13)]].values\n",
    "    return features, targets\n",
    "\n",
    "# Prepare Data\n",
    "scaler = StandardScaler()\n",
    "X_train, y_train = load_data('../Data/training.csv')\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test, y_test = load_data('../Data/testing.csv')\n",
    "X_test = scaler.transform(X_test)\n",
    "y_reference = pd.read_csv('../Data/reference.csv')[[f'f{i}' for i in range(1, 13)]].values\n",
    "\n",
    "train_dataset = CustomDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
    "test_dataset = CustomDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Model\n",
    "input_size = X_train.shape[1]\n",
    "output_size = y_train.shape[1]\n",
    "model = RegressionNN(input_size, output_size)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0055)\n",
    "\n",
    "# Train Model\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for features, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "# Evaluate Model\n",
    "model.eval()\n",
    "total_loss = 0\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for features, targets in test_loader:\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, targets)\n",
    "        total_loss += loss.item()\n",
    "        # Round the outputs to the nearest integer\n",
    "        rounded_outputs = torch.round(outputs).numpy()\n",
    "        predictions.extend(rounded_outputs)\n",
    "\n",
    "avg_loss = total_loss / len(test_loader)\n",
    "print(f'Average Testing Loss: {avg_loss}')\n",
    "\n",
    "# Compare with Reference and Calculate Accuracy\n",
    "accuracy_list = []\n",
    "for i in range(12):\n",
    "    correct = sum(1 for j in range(len(predictions)) if predictions[j][i] == y_reference[j][i])\n",
    "    accuracy = correct / len(predictions)\n",
    "    accuracy_list.append(accuracy)\n",
    "\n",
    "# Save results\n",
    "print('Monthly Accuracy:\\n')\n",
    "for i, acc in enumerate(accuracy_list, 1):\n",
    "    print(f'Month {i}: {acc:.2f}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classification Report for each month:\n",
      "\n",
      "\n",
      "Month 1 Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.88      0.60        33\n",
      "           2       0.40      0.15      0.22        27\n",
      "           3       0.20      0.17      0.18        12\n",
      "           4       0.45      0.31      0.37        16\n",
      "           5       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.42        96\n",
      "   macro avg       0.30      0.30      0.27        96\n",
      "weighted avg       0.37      0.42      0.35        96\n",
      "\n",
      "Accuracy for Month 1: 0.4166666666666667\n",
      "\n",
      "\n",
      "Month 2 Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.74      0.59        31\n",
      "           2       0.45      0.35      0.39        26\n",
      "           3       0.46      0.46      0.46        13\n",
      "           4       0.67      0.12      0.20        17\n",
      "           5       0.54      0.78      0.64         9\n",
      "\n",
      "    accuracy                           0.49        96\n",
      "   macro avg       0.52      0.49      0.46        96\n",
      "weighted avg       0.51      0.49      0.45        96\n",
      "\n",
      "Accuracy for Month 2: 0.4895833333333333\n",
      "\n",
      "\n",
      "Month 3 Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.40      0.50        15\n",
      "           2       0.42      0.74      0.54        19\n",
      "           3       0.26      0.36      0.30        22\n",
      "           4       0.40      0.07      0.12        27\n",
      "           5       0.44      0.62      0.52        13\n",
      "\n",
      "    accuracy                           0.40        96\n",
      "   macro avg       0.44      0.44      0.40        96\n",
      "weighted avg       0.42      0.40      0.36        96\n",
      "\n",
      "Accuracy for Month 3: 0.3958333333333333\n",
      "\n",
      "\n",
      "Month 4 Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.32      0.43      0.36        14\n",
      "           3       0.53      0.43      0.48        37\n",
      "           4       0.21      0.16      0.18        25\n",
      "           5       0.22      0.24      0.23        17\n",
      "\n",
      "    accuracy                           0.31        96\n",
      "   macro avg       0.26      0.25      0.25        96\n",
      "weighted avg       0.35      0.31      0.32        96\n",
      "\n",
      "Accuracy for Month 4: 0.3125\n",
      "\n",
      "\n",
      "Month 5 Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.15      0.38      0.21         8\n",
      "           2       0.23      0.33      0.27        15\n",
      "           3       0.66      0.54      0.59        50\n",
      "           4       0.30      0.25      0.27        12\n",
      "           5       1.00      0.27      0.43        11\n",
      "\n",
      "    accuracy                           0.43        96\n",
      "   macro avg       0.47      0.35      0.36        96\n",
      "weighted avg       0.54      0.43      0.45        96\n",
      "\n",
      "Accuracy for Month 5: 0.4270833333333333\n",
      "\n",
      "\n",
      "Month 6 Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.86      0.45        14\n",
      "           2       0.61      0.29      0.39        38\n",
      "           3       0.55      0.52      0.54        21\n",
      "           4       0.47      0.57      0.52        14\n",
      "           5       1.00      0.22      0.36         9\n",
      "\n",
      "    accuracy                           0.46        96\n",
      "   macro avg       0.59      0.49      0.45        96\n",
      "weighted avg       0.57      0.46      0.45        96\n",
      "\n",
      "Accuracy for Month 6: 0.4583333333333333\n",
      "\n",
      "\n",
      "Month 7 Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.80      0.59        20\n",
      "           2       0.38      0.30      0.33        20\n",
      "           3       0.50      0.39      0.44        23\n",
      "           4       0.45      0.28      0.34        18\n",
      "           5       0.65      0.73      0.69        15\n",
      "\n",
      "    accuracy                           0.49        96\n",
      "   macro avg       0.49      0.50      0.48        96\n",
      "weighted avg       0.48      0.49      0.47        96\n",
      "\n",
      "Accuracy for Month 7: 0.4895833333333333\n",
      "\n",
      "\n",
      "Month 8 Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.89      0.55        19\n",
      "           2       0.20      0.09      0.12        23\n",
      "           3       0.50      0.36      0.42        28\n",
      "           4       0.23      0.27      0.25        11\n",
      "           5       0.90      0.60      0.72        15\n",
      "\n",
      "    accuracy                           0.43        96\n",
      "   macro avg       0.45      0.44      0.41        96\n",
      "weighted avg       0.44      0.43      0.40        96\n",
      "\n",
      "Accuracy for Month 8: 0.4270833333333333\n",
      "\n",
      "\n",
      "Month 9 Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.62      0.37        16\n",
      "           2       0.45      0.17      0.24        30\n",
      "           3       0.70      0.66      0.68        35\n",
      "           4       0.33      0.40      0.36        10\n",
      "           5       0.50      0.20      0.29         5\n",
      "\n",
      "    accuracy                           0.45        96\n",
      "   macro avg       0.45      0.41      0.39        96\n",
      "weighted avg       0.50      0.45      0.44        96\n",
      "\n",
      "Accuracy for Month 9: 0.4479166666666667\n",
      "\n",
      "\n",
      "Month 10 Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.54      0.38        13\n",
      "           2       0.47      0.50      0.48        32\n",
      "           3       0.55      0.52      0.53        33\n",
      "           4       0.67      0.17      0.27        12\n",
      "           5       0.50      0.33      0.40         6\n",
      "\n",
      "    accuracy                           0.46        96\n",
      "   macro avg       0.50      0.41      0.41        96\n",
      "weighted avg       0.50      0.46      0.45        96\n",
      "\n",
      "Accuracy for Month 10: 0.4583333333333333\n",
      "\n",
      "\n",
      "Month 11 Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.40      0.32        15\n",
      "           2       0.53      0.47      0.50        38\n",
      "           3       0.39      0.44      0.41        27\n",
      "           4       0.25      0.17      0.20        12\n",
      "           5       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.40        96\n",
      "   macro avg       0.29      0.30      0.29        96\n",
      "weighted avg       0.39      0.40      0.39        96\n",
      "\n",
      "Accuracy for Month 11: 0.3958333333333333\n",
      "\n",
      "\n",
      "Month 12 Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.91      0.74        43\n",
      "           2       0.39      0.25      0.30        28\n",
      "           3       0.44      0.25      0.32        16\n",
      "           4       0.33      0.22      0.27         9\n",
      "\n",
      "    accuracy                           0.54        96\n",
      "   macro avg       0.45      0.41      0.41        96\n",
      "weighted avg       0.50      0.54      0.50        96\n",
      "\n",
      "Accuracy for Month 12: 0.5416666666666666\n",
      "\n",
      "\n",
      "Average Accuracy Across All Months: 0.4383680555555556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "train_df = pd.read_csv('../Data/training.csv')\n",
    "test_df = pd.read_csv('../Data/testing.csv')\n",
    "reference_df = pd.read_csv('../Data/reference.csv')\n",
    "\n",
    "X_train = train_df.drop(columns=[f'f{i}' for i in range(1, 13)])\n",
    "y_train = train_df[[f'f{i}' for i in range(1, 13)]]\n",
    "X_test = test_df.drop(columns=[f'f{i}' for i in range(1, 13)])\n",
    "y_test = reference_df[[f'f{i}' for i in range(1, 13)]]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "predictions = knn.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "print(\"KNN Classification Report for each month:\\n\")\n",
    "overall_accuracy = 0\n",
    "for i in range(1, 13):\n",
    "    report = classification_report(y_test[f'f{i}'], predictions[:, i-1], zero_division=0)\n",
    "    print(f\"\\nMonth {i} Report:\\n\")\n",
    "    print(report)\n",
    "    accuracy = accuracy_score(y_test[f'f{i}'], predictions[:, i-1])\n",
    "    overall_accuracy += accuracy\n",
    "    print(f\"Accuracy for Month {i}: {accuracy}\\n\")\n",
    "\n",
    "overall_accuracy /= 12\n",
    "print(f\"\\nAverage Accuracy Across All Months: {overall_accuracy}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
